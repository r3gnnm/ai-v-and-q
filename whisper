from faster_whisper import WhisperModel
from typing import List, Dict, Optional
from pathlib import Path
import json

class ASRService:
    """
    Распознавание речи с помощью Faster Whisper
    """
    
    def __init__(self, 
                 model_size: str = "base",
                 device: str = "cpu",
                 compute_type: str = "int8"):
        """
        Args:
            model_size: tiny, base, small, medium, large-v2, large-v3
            device: cpu или cuda
            compute_type: int8, float16, float32
        """
        print(f"Loading Whisper model: {model_size}")
        self.model = WhisperModel(
            model_size,
            device=device,
            compute_type=compute_type
        )
        self.model_size = model_size
    
    def transcribe(self,
                  audio_path: str,
                  language: Optional[str] = None,
                  task: str = "transcribe") -> Dict:
        """
        Транскрибировать аудио с временными метками
        
        Args:
            audio_path: путь к аудиофайлу
            language: язык (None для автоопределения)
            task: transcribe или translate
        
        Returns:
            dict с полным транскриптом и сегментами
        """
        audio_path = Path(audio_path)
        
        if not audio_path.exists():
            raise FileNotFoundError(f"Audio file not found: {audio_path}")
        
        print(f"Transcribing: {audio_path.name}")
        
        # Транскрибация
        segments, info = self.model.transcribe(
            str(audio_path),
            language=language,
            task=task,
            word_timestamps=True,  # включить timestamps для слов
            vad_filter=True,  # Voice Activity Detection
            vad_parameters=dict(
                min_silence_duration_ms=500,
                speech_pad_ms=400
            )
        )
        
        # Сбор результатов
        transcript_segments = []
        full_text = []
        
        for segment in segments:
            seg_data = {
                "id": segment.id,
                "start": segment.start,
                "end": segment.end,
                "text": segment.text.strip(),
                "words": []
            }
            
            # Добавление word-level timestamps
            if hasattr(segment, 'words') and segment.words:
                for word in segment.words:
                    seg_data["words"].append({
                        "word": word.word,
                        "start": word.start,
                        "end": word.end,
                        "probability": word.probability
                    })
            
            transcript_segments.append(seg_data)
            full_text.append(segment.text.strip())
        
        result = {
            "language": info.language,
            "language_probability": info.language_probability,
            "duration": info.duration,
            "full_text": " ".join(full_text),
            "segments": transcript_segments
        }
        
        return result
    
    def transcribe_with_speakers(self, audio_path: str) -> Dict:
        """
        Транскрибация с разделением на спикеров (требует дополнительной модели)
        Пока упрощенная версия - разделение по паузам
        """
        result = self.transcribe(audio_path)
        
        # Простая эвристика: новый спикер после паузы >2 сек
        current_speaker = "Speaker 1"
        speaker_count = 1
        
        for i, seg in enumerate(result["segments"]):
            if i > 0:
                prev_end = result["segments"][i-1]["end"]
                curr_start = seg["start"]
                pause_duration = curr_start - prev_end
                
                # Смена спикера при длинной паузе
                if pause_duration > 2.0:
                    speaker_count += 1
                    current_speaker = f"Speaker {speaker_count}"
            
            seg["speaker"] = current_speaker
        
        return result
    
    def save_transcript(self, 
                       transcript: Dict,
                       output_path: str,
                       format: str = "json"):
        """
        Сохранить транскрипт в файл
        
        Args:
            transcript: результат транскрибации
            output_path: путь для сохранения
            format: json, txt, srt, vtt
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if format == "json":
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(transcript, f, ensure_ascii=False, indent=2)
        
        elif format == "txt":
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(transcript["full_text"])
        
        elif format == "srt":
            self._save_as_srt(transcript, output_path)
        
        elif format == "vtt":
            self._save_as_vtt(transcript, output_path)
        
        else:
            raise ValueError(f"Unsupported format: {format}")
        
        print(f"Transcript saved: {output_path}")
    
    def _save_as_srt(self, transcript: Dict, output_path: Path):
        """Сохранить в SRT формате (субтитры)"""
        with open(output_path, 'w', encoding='utf-8') as f:
            for i, seg in enumerate(transcript["segments"], 1):
                start = self._format_timestamp_srt(seg["start"])
                end = self._format_timestamp_srt(seg["end"])
                text = seg["text"]
                
                f.write(f"{i}\n")
                f.write(f"{start} --> {end}\n")
                f.write(f"{text}\n\n")
    
    def _save_as_vtt(self, transcript: Dict, output_path: Path):
        """Сохранить в WebVTT формате"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("WEBVTT\n\n")
            
            for seg in transcript["segments"]:
                start = self._format_timestamp_vtt(seg["start"])
                end = self._format_timestamp_vtt(seg["end"])
                text = seg["text"]
                
                f.write(f"{start} --> {end}\n")
                f.write(f"{text}\n\n")
    
    @staticmethod
    def _format_timestamp_srt(seconds: float) -> str:
        """Форматировать timestamp для SRT (HH:MM:SS,mmm)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
    
    @staticmethod
    def _format_timestamp_vtt(seconds: float) -> str:
        """Форматировать timestamp для VTT (HH:MM:SS.mmm)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}.{millis:03d}"
    
    def get_text_at_timestamp(self, 
                             transcript: Dict,
                             start_time: float,
                             end_time: float) -> str:
        """
        Получить текст в заданном временном диапазоне
        
        Args:
            transcript: результат транскрибации
            start_time: начало в секундах
            end_time: конец в секундах
        
        Returns:
            текст в указанном диапазоне
        """
        relevant_segments = []
        
        for seg in transcript["segments"]:
            # Сегмент пересекается с диапазоном
            if seg["start"] < end_time and seg["end"] > start_time:
                relevant_segments.append(seg["text"])
        
        return " ".join(relevant_segments)


# Пример
if __name__ == "__main__":
    # Инициализация сервиса
    asr = ASRService(model_size="base", device="cpu")
    
    # Транскрибация
    audio_file = "output/audio.wav"
    result = asr.transcribe(audio_file, language="en")
    
    print(f"Language: {result['language']}")
    print(f"Duration: {result['duration']:.2f}s")
    print(f"\nFull text:\n{result['full_text'][:200]}...")
    
    # Сохранение
    asr.save_transcript(result, "output/transcript.json", format="json")
    asr.save_transcript(result, "output/transcript.srt", format="srt")
    asr.save_transcript(result, "output/transcript.txt", format="txt")
    
    # Получить текст в диапазоне
    text_segment = asr.get_text_at_timestamp(result, start_time=10.0, end_time=30.0)
    print(f"\nText from 10-30s:\n{text_segment}")
